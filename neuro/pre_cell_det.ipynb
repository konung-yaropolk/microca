{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion correction and cells detection\n",
    "---\n",
    "\n",
    "Pre-synaptic axonal terminals with GCamp5f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "try:\n",
    "    cv2.setNumThreads(8)\n",
    "except():\n",
    "    pass\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import yaml\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.motion_correction import MotionCorrect\n",
    "from caiman.source_extraction.cnmf import cnmf as cnmf\n",
    "from caiman.source_extraction.cnmf import params as params\n",
    "from caiman.source_extraction.cnmf import utilities as util\n",
    "\n",
    "from skimage.util import montage\n",
    "from skimage.filters import rank\n",
    "from skimage import morphology\n",
    "from skimage import exposure\n",
    "from skimage import measure\n",
    "from skimage import io\n",
    "\n",
    "from scipy.ndimage import measurements\n",
    "\n",
    "import bokeh.plotting as bpl\n",
    "import holoviews as hv\n",
    "bpl.output_notebook()\n",
    "hv.notebook_extension('bokeh')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input files path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_name = 'A0005'\n",
    "samp_path = os.path.join(''.join(sys.path[0].split('neuro')), 'data_neuro', samp_name)\n",
    "\n",
    "# sample YAML metadata file uploading\n",
    "with open(f'{samp_path}/{samp_name}_meta.yaml') as f:\n",
    "    samp_meta = yaml.safe_load(f)\n",
    "\n",
    "reg_name = 'pre_gcamp'\n",
    "reg_path = f'{samp_path}/{reg_name}.tif'\n",
    "\n",
    "reg_memmap = f'{samp_path}/pre_gcamp_d1_320_d2_320_d3_1_order_C_frames_1091.mmap'\n",
    "reg_fit = f'{samp_path}/{reg_name}_fit.hdf5'\n",
    "reg_refit = None  # f'{samp_path}/{reg_name}_refit.hdf5'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CaImAn parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data params\n",
    "file_path = [reg_path]\n",
    "fr = 1                      # imaging rate in frames per second\n",
    "decay_time = 3              # length of a typical transient in seconds (see source/Getting_Started.rst)\n",
    "dxy = (0.311, 0.311)        # spatial resolution of FOV in pixels per um\n",
    "\n",
    "# patch params\n",
    "rf =  100                    # half-size of the patches in pixels. e.g., if rf=25, patches are 50x50\n",
    "stride = 50                 # amount of overlap between the patches in pixels\n",
    "\n",
    "# pre-peocess params\n",
    "noise_method = 'logmexp'     # PSD averaging method for computing the noise std\n",
    "only_init = False\n",
    "\n",
    "# motion correction params\n",
    "max_deviation_rigid = 3     # maximum shifts deviation allowed for patch with respect to rigid shifts\n",
    "max_shifts = (10, 10)       # maximum allowed rigid shifts (in pixels)\n",
    "strides = (80, 80)          # start a new patch for pw-rigid motion correction every x pixels\n",
    "overlaps = (20, 20)         # overlap between pathes (size of patch strides+overlaps)\n",
    "pw_rigid = True             # flag for performing non-rigid motion correction\n",
    "\n",
    "# init params\n",
    "K = 10                           # number of components to be found (per patch or whole FOV depending on whether rf=None)\n",
    "gSig = [2, 2]                    # radius of average spatial components (in pixels)\n",
    "ssub = 4                         # spatial subsampling during initialization\n",
    "tsub = 2                         # temporal subsampling during intialization\n",
    "method_init = 'graph_nmf'       # initialization method ('sparse_nmf' NOT WORKING!),   'graph_nmf'\n",
    "seed_method = 'auto'             # methods for choosing seed pixels during greedy_roi or corr_pnr initialization\n",
    "\n",
    "# merge params\n",
    "merge_thr = 0.75                 # trace correlation threshold for merging two components.\n",
    "merge_parallel = False           # perform merging in parallel\n",
    "\n",
    "# spatial and temporal params\n",
    "nb = 2                           # number of global background components\n",
    "method_deconvolution = 'oasis'   # method for solving the constrained deconvolution problem ('oasis','cvx' or 'cvxpy') if method cvxpy, primary and secondary (if problem unfeasible for approx solution)\n",
    "noise_range = [0.25, 0.5]        # range of normalized frequencies over which to compute the PSD for noise determination\n",
    "noise_method = 'logmexp'         # PSD averaging method for computing the noise std\n",
    "p = 1                            # order of the autoregressive system\n",
    "\n",
    "# quality params\n",
    "quality_dict = {'min_SNR': 8,        # trace SNR threshold. Traces with SNR above this will get accepted\n",
    "                'SNR_lowest': 7,     # minimum required trace SNR. Traces with SNR below this will get rejected\n",
    "                'rval_thr': 0.4,     # space correlation threshold. Components with correlation higher than this will get accepted  \n",
    "                'rval_lowest': -2,  # minimum required space correlation. Components with correlation below this will get rejected\n",
    "                'use_cnn': False}    # flag for using the CNN classifier\n",
    "\n",
    "\n",
    "param_dict = {'fnames': file_path,\n",
    "              'fr': fr,\n",
    "              'decay_time': decay_time,\n",
    "              'dxy': dxy,\n",
    "              'rf': rf,\n",
    "              'stride': stride,\n",
    "              'noise_method': noise_method,\n",
    "              'only_init': only_init,\n",
    "              'max_deviation_rigid': max_deviation_rigid,\n",
    "              'max_shifts': max_shifts,\n",
    "              'strides': strides,\n",
    "              'overlaps': overlaps,\n",
    "              'pw_rigid': pw_rigid,\n",
    "              'K': K,\n",
    "              'gSig': gSig,\n",
    "              'ssub': ssub,\n",
    "              'tsub': tsub,\n",
    "              'method_init': method_init,\n",
    "              'seed_method': seed_method,\n",
    "              'merge_thr': merge_thr,\n",
    "              'merge_parallel': merge_parallel,\n",
    "              'nb': nb,\n",
    "              'method_deconvolution': method_deconvolution,\n",
    "              'noise_range': noise_range,\n",
    "              'noise_method': noise_method,\n",
    "              'p': p}\n",
    "\n",
    "param_dict.update(quality_dict)\n",
    "opts = params.CNMFParams(params_dict=param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(opts.quality)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion corection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if True - Ca channel demostration on\n",
    "display_movie = True\n",
    "if display_movie:\n",
    "    m_orig = cm.load_movie_chain(reg_path)\n",
    "    ds_ratio = 0.31\n",
    "    m_orig.resize(1, 1, ds_ratio).play(\n",
    "        q_max=99.5, fr=50, magnification=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start a cluster for parallel processing (if a cluster already exists it will be closed and a new session will be opened)\n",
    "if 'dview' in locals():\n",
    "    cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)\n",
    "\n",
    "mc = MotionCorrect(reg_path, dview=dview, **opts.get_group('motion'))\n",
    "\n",
    "mc.motion_correct(save_movie=True)\n",
    "m_els = cm.load(mc.fname_tot_els)\n",
    "border_to_0 = 0 if mc.border_nan == 'copy' else mc.border_to_0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results\n",
    "display_movie = True\n",
    "save_avi = True\n",
    "if display_movie:\n",
    "    m_orig = cm.load_movie_chain(reg_path)\n",
    "    ds_ratio = 0.2\n",
    "    cm.concatenate([m_orig.resize(1, 1, ds_ratio) - mc.min_mov*mc.nonneg_movie,\n",
    "                    m_els.resize(1, 1, ds_ratio)], \n",
    "                   axis=2).play(fr=30, q_max=99.5, magnification=1, offset=0, save_movie=save_avi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory map the file in order 'C' saving\n",
    "reg_mc = cm.save_memmap(mc.mmap_file, base_name=f'{reg_name}_', order='C',\n",
    "                        border_to_0=border_to_0) # exclude borders"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit & refit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(reg_memmap, str):\n",
    "    Yr, dims, T = cm.load_memmap(reg_memmap)\n",
    "else:\n",
    "    Yr, dims, T = cm.load_memmap(reg_mc)\n",
    "\n",
    "reg_images = np.reshape(Yr.T, [T] + list(dims), order='F') \n",
    "Cn = cm.local_correlations(reg_images, swap_dim=False)\n",
    "Cn[np.isnan(Cn)] = 0\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(Cn, cmap='magma')\n",
    "plt.show()\n",
    "\n",
    "save_reg_img = True\n",
    "if save_reg_img:\n",
    "    io.imsave(f'{samp_path}/{reg_name}_mov_cor.tif', reg_images)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit section"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start/restart cluster"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% start a cluster for parallel processing (if a cluster already exists it will be closed and a new session will be opened)\n",
    "if 'dview' in locals():\n",
    "    cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% restart cluster to clean up memory\n",
    "cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm = cnmf.CNMF(n_processes, params=opts, dview=dview)\n",
    "if isinstance(reg_fit, str):\n",
    "    cnm = cnmf.load_CNMF(reg_fit, n_processes=1, dview=dview)\n",
    "else:\n",
    "    cnm = cnm.fit(reg_images)\n",
    "    save_results = True\n",
    "    if save_results:\n",
    "        cnm.save(f'{samp_path}/{reg_name}_fit.hdf5')\n",
    "\n",
    "cnm.estimates.plot_contours_nb(img=Cn, cmap='magma')\n",
    "cnm.estimates.nb_view_components(img=Cn, idx=cnm.estimates.idx_components,cmap='magma')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm.params.set('quality', quality_dict)\n",
    "print(cnm.params.quality)\n",
    "\n",
    "cnm.estimates.evaluate_components(reg_images, cnm.params, dview=dview)\n",
    "\n",
    "cnm.estimates.threshold_spatial_components(maxthr=0.3, dview=dview)\n",
    "cnm.estimates.plot_contours_nb(img=Cn, idx=cnm.estimates.idx_components, cmap='magma')\n",
    "\n",
    "print(f'{len(cnm.estimates.idx_components)} good components: {cnm.estimates.idx_components}')\n",
    "print(f'{len(cnm.estimates.idx_components_bad)} bad')\n",
    "\n",
    "cnm.estimates.nb_view_components(img=Cn, idx=cnm.estimates.idx_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm.estimates.nb_view_components(img=Cn, idx=cnm.estimates.idx_components_bad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refit section"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(reg_refit, str):\n",
    "    cnm2 = cnmf.load_CNMF(reg_refit, n_processes=1, dview=dview)\n",
    "else:   \n",
    "    cnm2 = cnm.refit(reg_images, dview=dview)\n",
    "    save_results = True\n",
    "    if save_results:\n",
    "        cnm2.save(f'{samp_path}/{reg_name}_pre_refit.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm2.estimates.evaluate_components(reg_images, cnm.params, dview=dview)\n",
    "\n",
    "cnm.estimates.plot_contours_nb(img=Cn, idx=cnm.estimates.idx_components, cmap='magma')\n",
    "cnm2.estimates.plot_contours_nb(img=Cn, idx=cnm2.estimates.idx_components, cmap='magma')\n",
    "\n",
    "cnm2.estimates.nb_view_components(img=Cn, idx=cnm2.estimates.idx_components)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finalization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNMF selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_cnm = cnm\n",
    "print(fin_cnm.estimates.idx_components)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% restart cluster to clean up memory\n",
    "cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot & output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contour_grid_plot(samp_cnmf, samp_img):\n",
    "    A = samp_cnmf.estimates.A.toarray().reshape(samp_img.shape + (-1,), order='F').transpose([2, 0, 1])\n",
    "\n",
    "    w = 20\n",
    "    h = 20\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    columns = 4\n",
    "    rows = 4\n",
    "\n",
    "    for i in samp_cnmf.estimates.idx_components: \n",
    "        A_frame = A[i]\n",
    "        A_frame[A_frame != 0] = 1\n",
    "        A_frame = np.ma.masked_where(A_frame == 0, A_frame, copy=False)\n",
    "        A_contour = np.asarray(measure.find_contours(A_frame, level=0.5))\n",
    "\n",
    "    # for i in range(1, columns*rows +1):\n",
    "        img = np.random.randint(10, size=(h,w))\n",
    "        fig.add_subplot(rows, columns, i+1)\n",
    "        plt.imshow(samp_img, cmap='magma')\n",
    "        for contour in A_contour:\n",
    "            plt.plot(contour[:, 1], contour[:, 0], linewidth=1, color='r')\n",
    "        # plt.title.set_title(f'ROI {i+1}')\n",
    "        plt.title(f'ROI {i+1}')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def contour_set_save(samp_cnmf, samp_img,save_path):\n",
    "    img_path = f'{save_path}/pre_contours'\n",
    "    if not os.path.exists(img_path):\n",
    "        os.makedirs(img_path)\n",
    "\n",
    "    import matplotlib.colors\n",
    "    cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"black\",\"green\"])\n",
    "\n",
    "    A = samp_cnmf.estimates.A.toarray().reshape(samp_img.shape + (-1,), order='F').transpose([2, 0, 1])\n",
    "\n",
    "    for i in samp_cnmf.estimates.idx_components: \n",
    "        A_frame = A[i]\n",
    "        A_frame[A_frame != 0] = 1\n",
    "        A_frame = np.ma.masked_where(A_frame == 0, A_frame, copy=False)\n",
    "        A_contour = np.asarray(measure.find_contours(A_frame, level=0.5))\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(samp_img, cmap=cmap)\n",
    "        for contour in A_contour:\n",
    "            plt.plot(contour[:, 1], contour[:, 0], linewidth=1, color='r')\n",
    "        plt.title(f'ROI {i+1}')\n",
    "        plt.axis('off')\n",
    "        plt.savefig(f'{img_path}/ROI_{i+1}.png')\n",
    "\n",
    "def comp_contour_plot(samp_cnmf, samp_img, save_file=None):\n",
    "    \"\"\" All spatial components (A) contours overlap ctrl img\n",
    "\n",
    "    https://stackoverflow.com/questions/28779559/how-to-set-same-color-for-markers-and-lines-in-a-matplotlib-plot-loop\n",
    "\n",
    "    \"\"\"\n",
    "    A = samp_cnmf.estimates.A.toarray().reshape(samp_img.shape + (-1,), order='F').transpose([2, 0, 1])\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(samp_img, cmap='magma')\n",
    "    ax = plt.gca()\n",
    "\n",
    "    for i in samp_cnmf.estimates.idx_components: \n",
    "        A_frame = A[i]\n",
    "        A_frame[A_frame != 0] = 1\n",
    "        A_frame = np.ma.masked_where(A_frame == 0, A_frame, copy=False)\n",
    "        A_center = measurements.center_of_mass(A_frame)\n",
    "        A_contour = np.asarray(measure.find_contours(A_frame, level=0.5))\n",
    "\n",
    "        plt.imshow(A_frame, cmap='jet', alpha=.5)\n",
    "        color = next(ax._get_lines.prop_cycler)['color']\n",
    "        for cont in A_contour:            \n",
    "            plt.plot(cont[:, 1], cont[:, 0], linewidth=1.5, alpha=.75 ,color=color)\n",
    "        plt.annotate(f'ROI {i+1}',\n",
    "                    (A_center[1], A_center[0]),\n",
    "                    textcoords=\"offset points\",\n",
    "                    xytext=(2,2),\n",
    "                    ha='center',\n",
    "                    color='white',\n",
    "                    weight='bold',\n",
    "                    fontsize=10)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if isinstance(save_file, str):\n",
    "        plt.savefig(save_file, dpi=300)\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# def img_comp_save(samp_cnmf, samp_img,save_path):\n",
    "#     img_path = f'{save_path}/pre_corr_imgs'\n",
    "#     if not os.path.exists(img_path):\n",
    "#         os.makedirs(img_path)\n",
    "\n",
    "def dF_cascade_plot(samp_cnmf, y_shift=0.5, save_file=None):\n",
    "    plt.figure(figsize=(20, 8))\n",
    "\n",
    "    shift = 0\n",
    "    for i in samp_cnmf.estimates.idx_components:\n",
    "        df_prof = samp_cnmf.estimates.F_dff[i]\n",
    "        plt.plot(df_prof+shift, alpha=.5, label=f'ROI {i+1}')\n",
    "        shift -= y_shift\n",
    "\n",
    "    plt.vlines(x=[-20], ymin=[-0.2], ymax=[0.8], linewidth=3, color='k')\n",
    "    plt.text(x=-60, y=-0.5, s=\"100% ΔF/F\", size=15, rotation=90.)\n",
    "    plt.axis('off')\n",
    "    plt.legend(loc=1)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if isinstance(save_file, str):\n",
    "        plt.savefig(save_file, dpi=300)\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ΔF/F calc & ctrl plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_cnm.estimates.detrend_df_f(quantileMin=5, frames_window=500,\n",
    "                            flag_auto=True, use_fast=False, detrend_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contour_grid_plot(fin_cnm, Cn)\n",
    "comp_contour_plot(fin_cnm, Cn, save_file=f'{samp_path}/{samp_name}_comp_contours.png')\n",
    "dF_cascade_plot(fin_cnm, save_file=f'{samp_path}/{samp_name}_dF_profiles.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video output\n",
    "\n",
    "def contour_mov_save(samp_cnmf, samp_img, comp_i, save_path):\n",
    "    # img_path = f'{save_path}/pre_contours'\n",
    "    # if not os.path.exists(img_path):\n",
    "    #     os.makedirs(img_path)\n",
    "\n",
    "    import matplotlib.colors\n",
    "    from skimage import exposure\n",
    "    import matplotlib.cm as cm\n",
    "    import matplotlib.animation as animation\n",
    "\n",
    "    # samp_img = samp_img[:100]\n",
    "\n",
    "    cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"black\",\"green\"])\n",
    "    samp_img = exposure.equalize_adapthist(samp_img.astype(int), clip_limit=0.25)\n",
    "    v_min, v_max = np.min(samp_img), np.max(samp_img)\n",
    "\n",
    "    A = samp_cnmf.estimates.A.toarray().reshape(samp_img.shape[1:] + (-1,), order='F').transpose([2, 0, 1])\n",
    "    A_frame = A[comp_i]\n",
    "    A_frame[A_frame != 0] = 1\n",
    "    A_frame = np.ma.masked_where(A_frame == 0, A_frame, copy=False)\n",
    "    A_contour = np.asarray(measure.find_contours(A_frame, level=0.5))\n",
    "\n",
    "    frames = [] # for storing the generated images\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    for i in range(len(samp_img)):\n",
    "        img = plt.imshow(samp_img[i], cmap=cmap, animated=True, vmin=v_min, vmax=v_max)\n",
    "        plt.title(f'ROI {comp_i+1}')\n",
    "        plt.axis('off')\n",
    "        for contour in A_contour:\n",
    "            plt.plot(contour[:, 1], contour[:, 0], linewidth=1, color='r', alpha=.75)\n",
    "        frames.append([img])\n",
    "    ani = animation.ArtistAnimation(fig, frames, interval=50, blit=True,\n",
    "                                    repeat_delay=1000)\n",
    "    ani.save(f'{save_path}/{samp_name}_{reg_name}_ROI{comp_i+1}.mp4')\n",
    "    # plt.show()\n",
    "        # plt.figure(figsize=(10, 10))\n",
    "        # plt.imshow(samp_img, cmap=cmap)\n",
    "        # for contour in A_contour:\n",
    "        #     plt.plot(contour[:, 1], contour[:, 0], linewidth=1, color='r')\n",
    "        # plt.title(f'ROI {i+1}')\n",
    "        # plt.axis('off')\n",
    "        # plt.savefig(f'{img_path}/ROI_{i+1}.png')\n",
    "\n",
    "contour_mov_save(fin_cnm, reg_images, 10, samp_path)\n",
    "\n",
    "# # OpenCV\n",
    "# size = 320, 320\n",
    "# duration = 2\n",
    "# fps = 25\n",
    "# out = cv2.VideoWriter(f'{samp_path}/{samp_name}_{reg_name}.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (size[1], size[0]), False)\n",
    "\n",
    "# eq_images = exposure.equalize_adapthist(reg_images.astype(int), clip_limit=0.03)\n",
    "# eq_images[eq_images > np.min(eq_images)/0.1] = np.min(eq_images)\n",
    "\n",
    "# ratio = np.amax(eq_images) / 256\n",
    "# eq_images = (eq_images/ratio).astype('uint8')\n",
    "\n",
    "# for frame in eq_images:\n",
    "#     out.write(frame.astype('uint8'))\n",
    "# out.release()\n",
    "\n",
    "# contour_set_save(fin_cnm, exposure.equalize_adapthist(img_ctrl_green, clip_limit=0.025), samp_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output CSV saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prof_df(samp_cnmf, samp_img, samp_name, reg_time, save_path):\n",
    "    A = samp_cnmf.estimates.A.toarray().reshape(samp_img.shape[1:] + (-1,), order='F').transpose([2, 0, 1])\n",
    "\n",
    "    # init df\n",
    "    output_df = pd.DataFrame(columns=['reg_name',      # registration name\n",
    "                                      'indx',         # frame index\n",
    "                                      'time',          # registration time\n",
    "                                      'comp',          # component num\n",
    "                                      'profile_raw',   # component raw value, total mean\n",
    "                                      'profile_C',     # component denoised value\n",
    "                                      'profile_ddf'])   # component detrended ΔF/F value\n",
    "    \n",
    "    frame_num = samp_cnmf.estimates.C.shape[1]\n",
    "    i_col = range(frame_num)\n",
    "    time_col = np.linspace(0, reg_time, num=frame_num)\n",
    "    reg_name_col = np.full(frame_num, samp_name)\n",
    "\n",
    "    for component_num in samp_cnmf.estimates.idx_components:\n",
    "        component_col = np.full(samp_img.shape[0], component_num+1)\n",
    "        \n",
    "        A_frame = A[component_num]\n",
    "        A_mask = np.copy(A_frame)\n",
    "        A_mask != 0\n",
    "        A_mask = np.array(A_mask, dtype=bool)\n",
    "\n",
    "        # mean by spatial component mask\n",
    "        est_raw = np.asarray([np.mean(np.ma.masked_where(~A_mask, frame)) for frame in samp_img])\n",
    "\n",
    "        # temporal component\n",
    "        est_C = samp_cnmf.estimates.C[component_num]\n",
    "\n",
    "        # detrended temporal component\n",
    "        est_df = samp_cnmf.estimates.F_dff[component_num]\n",
    "        \n",
    "        component_df = pd.DataFrame({'reg_name':reg_name_col,\n",
    "                                     'indx':i_col,\n",
    "                                     'time':time_col,\n",
    "                                     'comp':component_col,\n",
    "                                     'profile_raw':est_raw,\n",
    "                                     'profile_C':est_C,\n",
    "                                     'profile_ddf':est_df})\n",
    "        output_df = pd.concat([output_df, component_df], ignore_index=True)\n",
    "\n",
    "    output_df.to_csv(f'{save_path}/{samp_name}_pre_comp_df.csv', index=False)\n",
    "    print(output_df.head())\n",
    "\n",
    "save_prof_df(samp_cnmf=fin_cnm,\n",
    "             samp_img=reg_images,\n",
    "             samp_name=samp_name,\n",
    "             reg_time=samp_meta['Reg_time'],\n",
    "             save_path=samp_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop cluster and clean up log files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caiman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "29b2b70970d54890c2ecd25b23b96024fbcef9a6a76cf3bb8bb780f56e497e25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
