{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a49ac22",
   "metadata": {},
   "source": [
    "# Peaks detection and features measurment\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad8eac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import yaml\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "import numpy as np\n",
    "import numpy.polynomial.polynomial as poly\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "from scipy import ndimage\n",
    "\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16e68eba",
   "metadata": {},
   "source": [
    "## Preprocessing & parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65d06f4c",
   "metadata": {},
   "source": [
    "#### Custom func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b702775a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_prof_to_arr(input_df):\n",
    "    \"\"\" Normilize raw Ca profiles in 0-1 range and convert data frame to numpy array\n",
    "    Return:\n",
    "        - np array (dims - [component, raw_prof, df_prof, norm_prof])\n",
    "        - dict ({component:raw_prof})\n",
    "\n",
    "    \"\"\"\n",
    "    output_arr = []\n",
    "    output_dict = {}\n",
    "    comp_list = np.array(input_df.comp.unique())\n",
    "    for comp in comp_list:\n",
    "        comp_raw_prof = np.array(input_df['profile_raw'][input_df['comp'] == comp])\n",
    "        comp_df_prof = np.array(input_df['profile_ddf'][input_df['comp'] == comp])\n",
    "        comp_norm_prof = preprocessing.minmax_scale(comp_raw_prof)\n",
    "        output_arr.append([comp_raw_prof, comp_df_prof, comp_norm_prof])\n",
    "        output_dict.update({comp:comp_raw_prof})\n",
    "    return np.asarray(output_arr), output_dict\n",
    "\n",
    "def ctrl_plot(input_df):\n",
    "    # raw profiles view\n",
    "    fig=px.line(input_df,\n",
    "                y='profile_ddf',\n",
    "                x='time',\n",
    "                color='comp',\n",
    "                animation_frame=\"comp\",\n",
    "                title='Individual components ﾎ認/F profiles')\n",
    "    fig.update(layout_yaxis_range = [min(input_df.profile_ddf), max(input_df.profile_ddf)])\n",
    "    fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b108137",
   "metadata": {},
   "source": [
    "#### Data uploading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933a8459",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_name = 'A0005'\n",
    "samp_path = os.path.join(''.join(sys.path[0].split('neuro')), 'data_neuro', samp_name)\n",
    "\n",
    "# sample YAML metadata file uploading\n",
    "with open(f'{samp_path}/{samp_name}_stim.yaml') as f:\n",
    "    samp_meta = yaml.safe_load(f)\n",
    "print(samp_meta)\n",
    "\n",
    "# sample data frame uploading\n",
    "pre_df = pd.read_csv(f'{samp_path}/{samp_name}_pre_comp_df.csv')\n",
    "print(pre_df.head())\n",
    "ctrl_plot(pre_df)\n",
    "\n",
    "# post_path = f'{samp_path}/{samp_name}_post_comp.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "963f0c3f",
   "metadata": {},
   "source": [
    "#### Sample global parameters, detection & measurment options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7c79b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global sample options\n",
    "total_reg_t = 1628.0  # E_0002 - 1634.0 F_7 - 1628.0 \n",
    "frame_time = total_reg_t / norm_profiles.shape[-1]\n",
    "\n",
    "reg_name = total_df.reg_name.unique()[0]\n",
    "\n",
    "time_line = np.linspace(0, total_reg_t, num=norm_profiles.shape[-1])\n",
    "\n",
    "# treatment options\n",
    "treatment_dict = {'BSA':[248.0, 590.0], 'C5a':[591.0, 1628.0]}  # E_0002 - {'C5a':[256., 628.]}  F_7 - {'BSA':[248.0, 590.0], 'BSA+C5a':[591.0, 1628.0]}\n",
    "application_lines_dict = {t:np.linspace(treatment_dict[t][0], treatment_dict[t][1]) for t in treatment_dict}\n",
    "\n",
    "# detection options\n",
    "min_distance_sec = 3\n",
    "min_distance_frames = int(min_distance_sec / frame_time)\n",
    "if min_distance_frames < 1:\n",
    "    min_distance_frames = 1\n",
    "\n",
    "width_sec = [1, 200]  # [min, max]\n",
    "width_frames = np.asanyarray([width_sec[0]/frame_time, width_sec[1]/frame_time], dtype=int)  # [min, max]\n",
    "\n",
    "plat_sec = [1, 500]  # [min, max]\n",
    "plat_frames = np.asarray([plat_sec[0]/frame_time, plat_sec[1]/frame_time], dtype=int)\n",
    "plat_frames[plat_frames == 0] = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e54a403f",
   "metadata": {},
   "source": [
    "#### Ctrl. profiles plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8929d4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "plt.figure(figsize=(20, 8))\n",
    "for one_prof in norm_profiles:\n",
    "    plt.plot(time_line, one_prof[1], alpha=.5)\n",
    "for app_name in application_lines_dict:\n",
    "    app_line = application_lines_dict[app_name]\n",
    "    plt.plot(app_line, [1.1] * len(app_line), label=app_name)\n",
    "plt.hlines(y=.5, xmin=0, xmax=np.max(time_line), linestyles='--', color='k')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "for one_prof in norm_profiles:\n",
    "    plt.plot(time_line, one_prof[0], alpha=.5)\n",
    "for app_name in application_lines_dict:\n",
    "    app_line = application_lines_dict[app_name]\n",
    "    plt.plot(app_line, [1.1] * len(app_line), label=app_name)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e9b4f0d",
   "metadata": {},
   "source": [
    "## ﾎ認/F profiles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f2ad564",
   "metadata": {},
   "source": [
    "#### Baseline fit experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6033c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_prof = norm_profiles[2][0]\n",
    "\n",
    "# polynomial fit baseline extraction\n",
    "coefs = poly.polyfit(time_line, in_prof, 2)\n",
    "base_prof = poly.polyval(time_line, coefs)\n",
    "\n",
    "# # HPF baseline extraction\n",
    "# sos = signal.butter(2, Wn=1, btype='lp', fs=1000, output='sos')\n",
    "# base_prof = signal.sosfilt(sos, in_prof)\n",
    "\n",
    "# # Asymmetric Least Squares Smoothing baseline extraction\n",
    "# from scipy import sparse\n",
    "# def baseline_als(y, lam=1, p=1e-100, niter=200):\n",
    "#   L = len(y)\n",
    "#   D = sparse.csc_matrix(np.diff(np.eye(L), 2))\n",
    "#   w = np.ones(L)\n",
    "#   for i in range(niter):\n",
    "#     W = sparse.spdiags(w, 0, L, L)\n",
    "#     Z = W + lam * D.dot(D.transpose())\n",
    "#     z = sparse.linalg.spsolve(Z, w*y)\n",
    "#     w = p * (y > z) + (1-p) * (y < z)\n",
    "#   return z\n",
    "# base_prof = baseline_als(in_prof)\n",
    "\n",
    "delta_prof = in_prof/base_prof - 1\n",
    "print(delta_prof)\n",
    "# plt.plot(delta_prof, alpha=.5)\n",
    "\n",
    "plt.plot(time_line, base_prof, alpha=.5)\n",
    "plt.plot(time_line, in_prof, alpha=.5)\n",
    "# plt.plot(time_line, in_prof - base_prof, alpha=.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48dd28b2",
   "metadata": {},
   "source": [
    "#### ﾎ認/F profiles plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cascade_prof_plot():\n",
    "    pass\n",
    "\n",
    "i = 0\n",
    "plt.figure(figsize=(20, 6))\n",
    "for one_comp_num in dict_raw_profiles.keys():\n",
    "    # if one_prof_num in selected_ROI:\n",
    "    one_prof = dict_raw_profiles[one_comp_num]\n",
    "    bese_coefs = poly.polyfit(time_line, one_prof, 2)\n",
    "    one_bese_prof = poly.polyval(time_line, coefs)\n",
    "    one_delta_plof = one_prof/one_bese_prof - 1\n",
    "    plt.plot(time_line, one_delta_plof+i, label=one_comp_num, alpha=.75)\n",
    "    i += 0.75\n",
    "\n",
    "for app_name in application_lines_dict:\n",
    "    app_line = application_lines_dict[app_name]\n",
    "    plt.plot(app_line, [-0.4] * len(app_line), label=app_name, linewidth=4)\n",
    "\n",
    "plt.vlines(x=[-10], ymin=[-0.4], ymax=[0.8], linewidth=3, color='k')\n",
    "plt.text(x=-40, y=-0.6, s=\"100% ﾎ認/F\", size=15, rotation=90.)\n",
    "\n",
    "plt.hlines(y=[-0.4], xmin=[-10], xmax=[190], linewidth=3, color='k')   # x bae  E0002 \n",
    "plt.text(x=50, y=-0.85, s=\"200 s\", size=15)                             # x bar  E0002 x 049\n",
    "\n",
    "plt.axis('off')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f24bb0b5",
   "metadata": {},
   "source": [
    "## Peaks detection with find_peaks only"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70632a40",
   "metadata": {},
   "source": [
    "#### Selected component peaks features plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bdc967",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_comp_profile = norm_profiles[4]\n",
    "\n",
    "comp_profile = one_comp_profile[1]#[300:800]\n",
    "time_line_demo = time_line#[300:800]\n",
    "\n",
    "# detection\n",
    "peaks, properties = signal.find_peaks(comp_profile,\n",
    "                                      height=None,\n",
    "                                      threshold=None,\n",
    "                                      distance=min_distance_frames,\n",
    "                                      wlen=80,\n",
    "                                      prominence=0.15,\n",
    "                                      rel_height=0.5,\n",
    "                                      width=width_frames,\n",
    "                                      plateau_size=plat_frames)\n",
    "prom = properties['prominences']\n",
    "# print(properties)\n",
    "\n",
    "# plotting\n",
    "prom_h = comp_profile[peaks] - prom\n",
    "width_w = np.sort(np.asarray([*properties['left_bases'], *properties['right_bases']], dtype=int))\n",
    "width_pairs =  np.asarray(list(zip(properties['left_bases'], properties['right_bases'])), dtype=int)\n",
    "\n",
    "app_y = [np.max(comp_profile)+np.max(comp_profile)*0.05] * len(app_line)\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(time_line_demo, comp_profile)\n",
    "plt.plot(time_line_demo[peaks], comp_profile[peaks], 'x', color='red')\n",
    "plt.plot(time_line_demo[width_w], comp_profile[width_w], '.', color='red')\n",
    "plt.vlines(x=time_line_demo[peaks], ymin=prom_h, ymax=comp_profile[peaks], color='red')\n",
    "\n",
    "for peak_width in width_pairs:\n",
    "    plt.fill_between(\n",
    "            x= time_line_demo[peak_width[0]:peak_width[1]], \n",
    "            y1= comp_profile[peak_width[0]:peak_width[1]], \n",
    "            color= \"red\",\n",
    "            alpha= 0.2)\n",
    "\n",
    "for app_name in application_lines_dict:\n",
    "    app_line = application_lines_dict[app_name]\n",
    "    plt.plot(app_line, [1.1] * len(app_line), label=app_name)\n",
    "    \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0679e121",
   "metadata": {},
   "source": [
    "#### All-components peaks detection & features data frame creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e365e4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# peaks features data frame init\n",
    "pf_df = pd.DataFrame(columns=['sample',          # sample name\n",
    "                              'comp',            # spatial component ID\n",
    "                              'app_group',       # application group, based on tretment_names & tretment_dict\n",
    "                              'peak_num',        # peak number in profile\n",
    "                              'peak_i',          # peal index in profile, frames\n",
    "                              'peak_time',       # peak time, sec\n",
    "                              'rise',            # rise time, sec\n",
    "                              'decay',           # decay time, sec\n",
    "                              'FWHM',            # full width at half maximum, sec\n",
    "                              'amp_abs',         # absolute amplitude, a.u.\n",
    "                              'prom_abs',        # prominence from raw profile, a.u.\n",
    "                              'integral_abs',    # signal integral in rise-decay window by raw profile\n",
    "                              'amp_dF',          # relative amplitude, ﾎ認/F\n",
    "                              'integral_dF',     # signal integral in rise-decay window by relative profile, ﾎ認/F\n",
    "                              'amp_norm',        # normalize amplitude, 0-1 range\n",
    "                              'prom_norm',       # prominence from normalized profile, 0-1 range\n",
    "                              'integral_norm'])  # signal integral in rise-decay window by normalized profile            \n",
    "\n",
    "components_ID = np.array(total_df.comp.unique())\n",
    "for component_num in range(norm_profiles.shape[0]):\n",
    "    comp_ID = components_ID[component_num]\n",
    "\n",
    "    comp_raw_profile = norm_profiles[component_num][0]\n",
    "    comp_norm_profile = norm_profiles[component_num][1]\n",
    "\n",
    "    comp_peaks, comp_properties = signal.find_peaks(comp_norm_profile,\n",
    "                                                    height=None,\n",
    "                                                    threshold=None,\n",
    "                                                    distance=min_distance_frames,\n",
    "                                                    wlen=80,\n",
    "                                                    prominence=0.15,\n",
    "                                                    rel_height=0.5,\n",
    "                                                    width=width_frames,\n",
    "                                                    plateau_size=plat_frames)\n",
    "                                                    \n",
    "    prom_raw = signal.peak_prominences(comp_raw_profile, comp_peaks, wlen=100)[0]\n",
    "\n",
    "    for peak_i in range(len(comp_peaks)):\n",
    "        # features calc\n",
    "        peak_index = comp_peaks[peak_i]\n",
    "        peak_time = time_line[peak_index]\n",
    "\n",
    "        # treatment group\n",
    "        treatment_list = list(treatment_dict.values())\n",
    "        for treatment in treatment_dict:\n",
    "            treatment_time = treatment_dict[treatment]\n",
    "            if peak_time < treatment_list[0][0]:\n",
    "                app_group = 'ctrl'\n",
    "            elif peak_time > treatment_list[-1][-1]:\n",
    "                app_group = 'wash'\n",
    "            elif peak_time >= treatment_time[0] and peak_time <= treatment_time[1]:\n",
    "                app_group = treatment\n",
    "\n",
    "        # high features section\n",
    "        amp_abs = comp_raw_profile[peak_index]\n",
    "        amp_norm = comp_norm_profile[peak_index]\n",
    "\n",
    "        prom_abs = prom_raw[peak_i]\n",
    "        prom_norm = comp_properties['prominences'][peak_i]\n",
    "\n",
    "        # time features section\n",
    "        rise = peak_index - comp_properties['left_bases'][peak_i]\n",
    "        decay = comp_properties['right_bases'][peak_i] - peak_index\n",
    "\n",
    "        fwhm = comp_properties['widths'][peak_i]\n",
    "        \n",
    "        # signal integral section\n",
    "        peak_bool_mask = np.zeros_like(comp_norm_profile, dtype=bool)\n",
    "        peak_bool_mask[comp_properties['left_bases'][peak_i]:comp_properties['right_bases'][peak_i]] = 1\n",
    "        integral_abs = np.sum(comp_raw_profile, where=peak_bool_mask)\n",
    "        integral_norm = np.sum(comp_norm_profile, where=peak_bool_mask)\n",
    "\n",
    "        # ﾎ認/F section\n",
    "            # NOT WORKING BECAUSE OF DOUBLE-PEAKS\n",
    "            # delta_win_r_i = comp_properties['left_bases'][peak_i] - delta_win_shift\n",
    "            # delta_win_l_i = delta_win_r_i - delta_win_size\n",
    "            # F0_val = np.mean(comp_raw_profile[delta_win_l_i:delta_win_r_i])\n",
    "            # amp_dF = (amp_abs-F0_val) / F0_val\n",
    "\n",
    "        amp_dF = prom_abs / (amp_abs - prom_abs)\n",
    "        # print(amp_dF)\n",
    "\n",
    "        peak_slice = comp_raw_profile[comp_properties['left_bases'][peak_i]:comp_properties['right_bases'][peak_i]]\n",
    "        peak_dF = peak_slice / (amp_abs - prom_abs)\n",
    "        # print(peak_slice)\n",
    "        # print(peak_dF)\n",
    "        integral_dF = np.sum(peak_dF)\n",
    "        \n",
    "    \n",
    "        # data frame update\n",
    "        pf_row = pd.DataFrame({'sample':[reg_name],               # sample name\n",
    "                               'comp':[comp_ID+1],                  # spatial component ID\n",
    "                               'app_group':[app_group],           # application group, before/after bath application\n",
    "                               'peak_num':[peak_i],               # peak number in profile\n",
    "                               'peak_i':[peak_index],             # peak index in profile, frames\n",
    "                               'peak_time':[peak_time],           # peak time, sec\n",
    "                               'rise':[rise * frame_time],        # rise time, sec\n",
    "                               'decay':[decay * frame_time],      # decay time, sec\n",
    "                               'FWHM':[fwhm * frame_time],        # full width at half maximum, sec  \n",
    "                               'amp_abs':[amp_abs],               # absolute amplitude, a.u.\n",
    "                               'prom_abs':[prom_abs],             # prominence from raw profile, a.u.\n",
    "                               'integral_abs':[integral_abs],     # signal integral in rise-decay window from raw profile\n",
    "                               'amp_dF':[amp_dF],                 # relative amplitude, ﾎ認/F\n",
    "                               'integral_dF':[integral_dF],       # signal integral in rise-decay window by relative profile, ﾎ認/F\n",
    "                               'amp_norm':[amp_norm],             # normalize amplitude, 0-1 range\n",
    "                               'prom_norm':[prom_norm],           # prominence from normalized profile, 0-1 range\n",
    "                               'integral_norm':[integral_norm]})  # signal integral in rise-decay window from normalized profile      \n",
    "        pf_df = pd.concat([pf_df, pf_row], ignore_index=True)\n",
    "\n",
    "print(pf_df)\n",
    "pf_df.to_csv(f'{reg_name}_output.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a02a26e",
   "metadata": {},
   "source": [
    "## Peaks detection with custom detector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5ec9b6f",
   "metadata": {},
   "source": [
    "#### Custom func."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a18f855",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prof_peaks_plot(input_profile, peaks_i, peaks_prop, x_time=None, add_profile=None):\n",
    "    \"\"\" SciPy find_peaks results for individual profile plotting,\n",
    "    for 0-1 range scaling profile only\n",
    "\n",
    "    \"\"\"\n",
    "    # features calc\n",
    "    if x_time is None:\n",
    "        x_time = np.linspace(0, input_profile.shape[0], input_profile.shape[0])\n",
    "    prom = peaks_prop['prominences']\n",
    "    prom_h = input_profile[peaks_i] - prom\n",
    "    width_w = np.sort(np.asarray([*peaks_prop['left_bases'], *peaks_prop['right_bases']], dtype=int))\n",
    "    width_pairs =  np.asarray(list(zip(peaks_prop['left_bases'], peaks_prop['right_bases'])), dtype=int)\n",
    "    fwhm_y = peaks_prop['width_heights']\n",
    "    fwhm_l = x_time[np.asarray(peaks_prop['left_ips'], dtype=int)]\n",
    "    fwhm_r = x_time[np.asarray(peaks_prop['right_ips'], dtype=int)]\n",
    "\n",
    "    # plotting\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    plt.plot(x_time, input_profile)\n",
    "    plt.plot(x_time[peaks_i], input_profile[peaks_i], 'x', color='red')\n",
    "    plt.plot(x_time[width_w], input_profile[width_w], '.', color='red')\n",
    "    plt.vlines(x=x_time[peaks_i], ymin=prom_h, ymax=input_profile[peaks_i], color='red')\n",
    "    plt.hlines(y=fwhm_y, xmin=fwhm_l, xmax=fwhm_r, color='red')\n",
    "    plt.hlines(y=.5, xmin=0, xmax=np.max(x_time), linestyles='--', color='k')\n",
    "    plt.fill_between(x=x_time,\n",
    "                     y1=input_profile,\n",
    "                     y2=.5,\n",
    "                     color='y',\n",
    "                     alpha=.2,\n",
    "                     where=input_profile>=.5)\n",
    "    for peak_width in width_pairs:\n",
    "        plt.fill_between(x= x_time[peak_width[0]:peak_width[1]], \n",
    "                         y1= input_profile[peak_width[0]:peak_width[1]], \n",
    "                         color= \"red\",\n",
    "                         alpha= 0.2)\n",
    "    if add_profile is not None:\n",
    "        plt.plot(x_time, add_profile, color='g', alpha=.25)\n",
    "    # plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25ebf737",
   "metadata": {},
   "source": [
    "#### Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74015b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel section\n",
    "x = np.linspace(0, 10, 100)\n",
    "\n",
    "# exp kernel\n",
    "y = 1 / np.exp(np.linspace(0, 9, 90))\n",
    "y = np.concatenate([np.zeros(10), y])\n",
    "\n",
    "tau = 0.75\n",
    "y_1 = 1 / np.exp(np.linspace(0, 9, 90) * tau)\n",
    "y_1 = np.concatenate([np.zeros(10), y_1])\n",
    "\n",
    "# square kernel\n",
    "y_2 = np.zeros(100)\n",
    "y_2[10:60] = 1\n",
    "\n",
    "\n",
    "# conv section\n",
    "one_comp_profile = norm_profiles[2]  # <=================================\n",
    "prof_raw = one_comp_profile[0]\n",
    "\n",
    "conv_raw = ndimage.convolve1d(prof_raw, y_1)\n",
    "conv_1 = ndimage.convolve1d(prof_raw, y_1)\n",
    "\n",
    "# scaling 0-1\n",
    "prof = preprocessing.minmax_scale(prof_raw)\n",
    "conv = preprocessing.minmax_scale(conv_raw)\n",
    "\n",
    "# convolved vector shift compensation\n",
    "prof_max = np.argmax(prof[:int(prof.shape[0]/4)])\n",
    "conv_max = np.argmax(conv[:int(conv.shape[0]/4)])\n",
    "conv_shift = prof_max - conv_max\n",
    "conv = np.concatenate([np.zeros(conv_shift), conv[:-conv_shift]])\n",
    "\n",
    "# debug plot\n",
    "debug_plot = False\n",
    "if debug_plot:\n",
    "    # kernel plot\n",
    "    plt.plot(x, y, color='b', alpha=.5, label='tau=1')\n",
    "    plt.plot(x, y_1, color='r', alpha=.5, label=f'tau={tau}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # conv plot\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    plt.plot(prof, color='b', alpha=.25, label='raw')\n",
    "    plt.plot(conv, color='r', alpha=.75, label='tau=1')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# detection\n",
    "peaks, properties = signal.find_peaks(conv,\n",
    "                                      height=None,\n",
    "                                      threshold=None,\n",
    "                                      distance=min_distance_frames,\n",
    "                                      wlen=100,\n",
    "                                      prominence=0.04,\n",
    "                                      rel_height=0.5,\n",
    "                                      width=width_frames)\n",
    "\n",
    "# peaks plot without plat det\n",
    "prof_peaks_plot(input_profile=conv, peaks_i=peaks, peaks_prop=properties, x_time=time_line, add_profile=prof)\n",
    "\n",
    "\n",
    "# plateau peaks merging\n",
    "plat_th = 0.5\n",
    "bases_arr = np.asarray([conv[properties['left_bases']],conv[properties['right_bases']]]).T\n",
    "\n",
    "if np.any(bases_arr < plat_th):\n",
    "    bases_i_arr = np.asarray([properties['left_bases'],properties['right_bases']]).T\n",
    "    bad_bases = np.asarray([np.zeros(2) if all(i<plat_th) else i for i in bases_arr])  # np.asarray([i for i in bases_arr if any(i>=0.5)])\n",
    "\n",
    "    # plat extraction\n",
    "    plat_i = np.asarray([True if any(b>=plat_th) else False for b in bases_arr])\n",
    "    plat_mask,_ = ndimage.label(plat_i)\n",
    "    plat_ends = [[bases_arr[plat_mask == p_n][0][0], bases_arr[plat_mask == p_n][-1][1]] for p_n in np.trim_zeros(np.unique(plat_mask))]  # plat ends extraction\n",
    "    plat_ends_i = [[bases_i_arr[plat_mask == p_n][0][0], bases_i_arr[plat_mask == p_n][-1][1]] for p_n in np.trim_zeros(np.unique(plat_mask))]  # plat ends index extraction\n",
    "\n",
    "    # print(plat_ends_i)\n",
    "    # print(plat_ends)\n",
    "\n",
    "    # plat features calc\n",
    "    prom_win_scale = 2\n",
    "    plat_prom_win = max([b[1]-b[0] for b in plat_ends_i]) * prom_win_scale\n",
    "    plat_peaks = [np.argmax(conv[b[0]:b[1]])+b[0] for b in plat_ends_i]\n",
    "\n",
    "    print(plat_ends_i)\n",
    "    print(plat_prom_win)\n",
    "\n",
    "\n",
    "    plat_prom = signal.peak_prominences(conv, plat_peaks, wlen=plat_prom_win)\n",
    "    plat_w = signal.peak_widths(conv, plat_peaks, rel_height=0.5, prominence_data=plat_prom)\n",
    "\n",
    "    print(plat_prom)\n",
    "\n",
    "    # prop update\n",
    "    # full_peaks = np.delete(peaks, plat_i)\n",
    "    # full_peaks = np.concatenate((full_peaks, plat_peaks))\n",
    "    peaks = np.concatenate((np.delete(peaks, plat_i), plat_peaks))\n",
    "\n",
    "    properties.update({'prominences':np.concatenate((np.delete(properties['prominences'], plat_i), plat_prom[0]))})\n",
    "    properties.update({'left_bases':np.concatenate((np.delete(properties['left_bases'], plat_i), plat_prom[1]))})\n",
    "    properties.update({'right_bases':np.concatenate((np.delete(properties['right_bases'], plat_i), plat_prom[2]))})\n",
    "    properties.update({'widths':np.concatenate((np.delete(properties['widths'], plat_i), plat_w[0]))})\n",
    "    properties.update({'width_heights':np.concatenate((np.delete(properties['width_heights'], plat_i), plat_w[1]))})\n",
    "    properties.update({'left_ips':np.concatenate((np.delete(properties['left_ips'], plat_i), plat_w[2]))})\n",
    "    properties.update({'right_ips':np.concatenate((np.delete(properties['right_ips'], plat_i), plat_w[3]))})\n",
    "\n",
    "# peaks plot with plat det\n",
    "prof_peaks_plot(input_profile=conv, peaks_i=peaks, peaks_prop=properties, x_time=time_line, add_profile=prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed9dd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class p_det():\n",
    "    \"\"\" Detector class\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caiman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "29b2b70970d54890c2ecd25b23b96024fbcef9a6a76cf3bb8bb780f56e497e25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
