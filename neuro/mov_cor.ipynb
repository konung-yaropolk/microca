{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion correction only\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "try:\n",
    "    cv2.setNumThreads(8)\n",
    "except():\n",
    "    pass\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import yaml\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.motion_correction import MotionCorrect\n",
    "from caiman.source_extraction.cnmf import cnmf as cnmf\n",
    "from caiman.source_extraction.cnmf import params as params\n",
    "from caiman.source_extraction.cnmf import utilities as util\n",
    "\n",
    "from skimage.util import montage\n",
    "from skimage.filters import rank\n",
    "from skimage import morphology\n",
    "from skimage import exposure\n",
    "from skimage import measure\n",
    "from skimage import io\n",
    "\n",
    "from scipy.ndimage import measurements\n",
    "\n",
    "import bokeh.plotting as bpl\n",
    "import holoviews as hv\n",
    "bpl.output_notebook()\n",
    "hv.notebook_extension('bokeh')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input files path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_name = 'A0013'\n",
    "samp_type = 'pre'\n",
    "samp_path = os.path.join(''.join(sys.path[0].split('neuro')), 'data_neuro', samp_name)\n",
    "\n",
    "reg_path = f'{samp_path}/{samp_name}_{samp_type}.tif'\n",
    "print(reg_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CaImAn parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data params\n",
    "file_path = [reg_path]\n",
    "fr = 1                      # imaging rate in frames per second\n",
    "decay_time = 3              # length of a typical transient in seconds (see source/Getting_Started.rst)\n",
    "dxy = (0.311, 0.311)        # spatial resolution of FOV in pixels per um\n",
    "\n",
    "# patch params\n",
    "rf =  100                    # half-size of the patches in pixels. e.g., if rf=25, patches are 50x50\n",
    "stride = 50                 # amount of overlap between the patches in pixels\n",
    "\n",
    "# pre-peocess params\n",
    "noise_method = 'logmexp'     # PSD averaging method for computing the noise std\n",
    "only_init = False\n",
    "\n",
    "# motion correction params\n",
    "max_deviation_rigid = 3     # maximum shifts deviation allowed for patch with respect to rigid shifts\n",
    "max_shifts = (10, 10)       # maximum allowed rigid shifts (in pixels)\n",
    "strides = (80, 80)          # start a new patch for pw-rigid motion correction every x pixels\n",
    "overlaps = (20, 20)         # overlap between pathes (size of patch strides+overlaps)\n",
    "pw_rigid = True             # flag for performing non-rigid motion correction\n",
    "\n",
    "# init params\n",
    "K = 10                           # number of components to be found (per patch or whole FOV depending on whether rf=None)\n",
    "gSig = [2, 2]                    # radius of average spatial components (in pixels)\n",
    "ssub = 4                         # spatial subsampling during initialization\n",
    "tsub = 2                         # temporal subsampling during intialization\n",
    "method_init = 'graph_nmf'       # initialization method ('sparse_nmf' NOT WORKING!),   'graph_nmf'\n",
    "seed_method = 'auto'             # methods for choosing seed pixels during greedy_roi or corr_pnr initialization\n",
    "\n",
    "# merge params\n",
    "merge_thr = 0.75                 # trace correlation threshold for merging two components.\n",
    "merge_parallel = False           # perform merging in parallel\n",
    "\n",
    "# spatial and temporal params\n",
    "nb = 2                           # number of global background components\n",
    "method_deconvolution = 'oasis'   # method for solving the constrained deconvolution problem ('oasis','cvx' or 'cvxpy') if method cvxpy, primary and secondary (if problem unfeasible for approx solution)\n",
    "noise_range = [0.25, 0.5]        # range of normalized frequencies over which to compute the PSD for noise determination\n",
    "noise_method = 'logmexp'         # PSD averaging method for computing the noise std\n",
    "p = 1                            # order of the autoregressive system\n",
    "\n",
    "# quality params\n",
    "quality_dict = {'min_SNR': 8,        # trace SNR threshold. Traces with SNR above this will get accepted\n",
    "                'SNR_lowest': 7,     # minimum required trace SNR. Traces with SNR below this will get rejected\n",
    "                'rval_thr': 0.4,     # space correlation threshold. Components with correlation higher than this will get accepted  \n",
    "                'rval_lowest': -2,  # minimum required space correlation. Components with correlation below this will get rejected\n",
    "                'use_cnn': False}    # flag for using the CNN classifier\n",
    "\n",
    "\n",
    "param_dict = {'fnames': file_path,\n",
    "              'fr': fr,\n",
    "              'decay_time': decay_time,\n",
    "              'dxy': dxy,\n",
    "              'rf': rf,\n",
    "              'stride': stride,\n",
    "              'noise_method': noise_method,\n",
    "              'only_init': only_init,\n",
    "              'max_deviation_rigid': max_deviation_rigid,\n",
    "              'max_shifts': max_shifts,\n",
    "              'strides': strides,\n",
    "              'overlaps': overlaps,\n",
    "              'pw_rigid': pw_rigid,\n",
    "              'K': K,\n",
    "              'gSig': gSig,\n",
    "              'ssub': ssub,\n",
    "              'tsub': tsub,\n",
    "              'method_init': method_init,\n",
    "              'seed_method': seed_method,\n",
    "              'merge_thr': merge_thr,\n",
    "              'merge_parallel': merge_parallel,\n",
    "              'nb': nb,\n",
    "              'method_deconvolution': method_deconvolution,\n",
    "              'noise_range': noise_range,\n",
    "              'noise_method': noise_method,\n",
    "              'p': p}\n",
    "\n",
    "param_dict.update(quality_dict)\n",
    "opts = params.CNMFParams(params_dict=param_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion corection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if True - Ca channel demostration on\n",
    "display_movie = False\n",
    "if display_movie:\n",
    "    m_orig = cm.load_movie_chain(reg_path)\n",
    "    ds_ratio = 0.31\n",
    "    m_orig.resize(1, 1, ds_ratio).play(\n",
    "        q_max=99.5, fr=50, magnification=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start a cluster for parallel processing (if a cluster already exists it will be closed and a new session will be opened)\n",
    "if 'dview' in locals():\n",
    "    cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)\n",
    "\n",
    "mc = MotionCorrect(reg_path, dview=dview, **opts.get_group('motion'))\n",
    "\n",
    "mc.motion_correct(save_movie=True)\n",
    "m_els = cm.load(mc.fname_tot_els)\n",
    "border_to_0 = 0 if mc.border_nan == 'copy' else mc.border_to_0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory map the file in order 'C' saving\n",
    "reg_mc = cm.save_memmap(mc.mmap_file, base_name=f'{samp_name}_{samp_type}_', order='C',\n",
    "                        border_to_0=border_to_0) # exclude borders\n",
    "\n",
    "Yr, dims, T = cm.load_memmap(reg_mc)\n",
    "\n",
    "reg_images = np.reshape(Yr.T, [T] + list(dims), order='F') \n",
    "Cn = cm.local_correlations(reg_images, swap_dim=False)\n",
    "Cn[np.isnan(Cn)] = 0\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(Cn, cmap='magma')\n",
    "plt.show()\n",
    "\n",
    "save_reg_img = True\n",
    "if save_reg_img:\n",
    "    io.imsave(f'{samp_path}/{samp_name}_{samp_type}_mov_cor.tif', reg_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% STOP CLUSTER and clean up log files\n",
    "cm.stop_server(dview=dview)\n",
    "log_files = glob.glob('*_LOG_*')\n",
    "for log_file in log_files:\n",
    "    os.remove(log_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caiman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "29b2b70970d54890c2ecd25b23b96024fbcef9a6a76cf3bb8bb780f56e497e25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
