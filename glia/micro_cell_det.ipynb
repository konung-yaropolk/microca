{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion correction and cells detection\n",
    "---\n",
    "\n",
    "Microglia cells with tdTomato + GCamp5f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# try:\n",
    "#     cv2.setNumThreads(8)\n",
    "# except:\n",
    "#     pass\n",
    "\n",
    "import os\n",
    "# import sys\n",
    "import glob\n",
    "# import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tiffile as tiff\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.motion_correction import MotionCorrect\n",
    "from caiman.source_extraction.cnmf import cnmf as cnmf\n",
    "from caiman.source_extraction.cnmf import params as params\n",
    "# from caiman.source_extraction.cnmf import utilities as util\n",
    "\n",
    "# from skimage.util import montage\n",
    "# from skimage.filters import rank\n",
    "# from skimage import morphology\n",
    "# from skimage import exposure\n",
    "from skimage import measure\n",
    "\n",
    "from scipy.ndimage import measurements\n",
    "\n",
    "import bokeh.plotting as bpl\n",
    "import holoviews as hv\n",
    "bpl.output_notebook()\n",
    "hv.notebook_extension('bokeh')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input files path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'A_0008_ch1'\n",
    "\n",
    "path = 'C:/Users/yandrianov'\n",
    "\n",
    "path_file = f'{path}/{file}.tif'\n",
    "\n",
    "\n",
    "file_fit = None # f'{path}/{file}_fit.hdf5'\n",
    "file_refit = None #f'{path}/{file}_refit.hdf5'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CaImAn parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data params\n",
    "file_list = [path_file]\n",
    "fr = 1                     # imaging rate in frames per second\n",
    "decay_time = 3              # length of a typical transient in seconds (see source/Getting_Started.rst)\n",
    "dxy = (0.311, 0.311)        # spatial resolution of FOV in pixels per um\n",
    "\n",
    "# patch params\n",
    "rf =  160                    # half-size of the patches in pixels. e.g., if rf=25, patches are 50x50\n",
    "stride = 0                 # amount of overlap between the patches in pixels\n",
    "\n",
    "# pre-peocess params\n",
    "noise_method = 'logmexp'     # PSD averaging method for computing the noise std\n",
    "only_init = False\n",
    "\n",
    "# motion correction params\n",
    "max_deviation_rigid = 3     # maximum shifts deviation allowed for patch with respect to rigid shifts\n",
    "max_shifts = (30, 30)       # maximum allowed rigid shifts (in pixels)\n",
    "strides = (160, 160)          # start a new patch for pw-rigid motion correction every x pixels\n",
    "overlaps = (20, 20)         # overlap between pathes (size of patch strides+overlaps)\n",
    "pw_rigid = True             # flag for performing non-rigid motion correction\n",
    "\n",
    "# init params\n",
    "K = 4                            # number of components to be found (per patch or whole FOV depending on whether rf=None)\n",
    "gSig = [15, 15]                  # radius of average spatial components (in pixels)\n",
    "ssub = 5                         # spatial subsampling during initialization\n",
    "tsub = 2                         # temporal subsampling during intialization\n",
    "method_init = 'greedy_roi'       # initialization method ('sparse_nmf' NOT WORKING!),   'graph_nmf'\n",
    "seed_method = 'auto'             # methods for choosing seed pixels during greedy_roi or corr_pnr initialization\n",
    "\n",
    "# merge params\n",
    "merge_thr = 0.1                  # trace correlation threshold for merging two components.\n",
    "merge_parallel = True            # perform merging in parallel\n",
    "\n",
    "# spatial and temporal params\n",
    "nb = 2                           # number of global background components\n",
    "method_deconvolution = 'oasis'   # method for solving the constrained deconvolution problem ('oasis','cvx' or 'cvxpy') if method cvxpy, primary and secondary (if problem unfeasible for approx solution)\n",
    "noise_range = [0.25, 0.5]        # range of normalized frequencies over which to compute the PSD for noise determination\n",
    "noise_method = 'logmexp'         # PSD averaging method for computing the noise std\n",
    "p = 2                            # order of the autoregressive system\n",
    "\n",
    "# quality params\n",
    "min_SNR = 5                      # trace SNR threshold. Traces with SNR above this will get accepted\n",
    "SNR_lowest = 2                   # minimum required trace SNR. Traces with SNR below this will get rejected\n",
    "rval_thr = 0.65                  # space correlation threshold. Components with correlation higher than this will get accepted                 \n",
    "rval_lowest = -2                 # minimum required space correlation. Components with correlation below this will get rejected\n",
    "use_cnn = False                  # flag for using the CNN classifier\n",
    "\n",
    "\n",
    "param_dict = {'fnames': file_list,\n",
    "              'fr': fr,\n",
    "              'decay_time': decay_time,\n",
    "              'dxy': dxy,\n",
    "              'rf': rf,\n",
    "              'stride': stride,\n",
    "              'noise_method': noise_method,\n",
    "              'only_init': only_init,\n",
    "              'max_deviation_rigid': max_deviation_rigid,\n",
    "              'max_shifts': max_shifts,\n",
    "              'strides': strides,\n",
    "              'overlaps': overlaps,\n",
    "              'pw_rigid': pw_rigid,\n",
    "              'K': K,\n",
    "              'gSig': gSig,\n",
    "              'ssub': ssub,\n",
    "              'tsub': tsub,\n",
    "              'method_init': method_init,\n",
    "              'seed_method': seed_method,\n",
    "              'merge_thr': merge_thr,\n",
    "              'merge_parallel': merge_parallel,\n",
    "              'nb': nb,\n",
    "              'method_deconvolution': method_deconvolution,\n",
    "              'noise_range': noise_range,\n",
    "              'noise_method': noise_method,\n",
    "              'p': p,\n",
    "              'min_SNR': min_SNR,\n",
    "              'SNR_lowest': SNR_lowest,\n",
    "              'rval_thr': rval_thr,\n",
    "              'rval_lowest': rval_lowest,\n",
    "              'use_cnn': use_cnn}\n",
    "\n",
    "print(file_list, '- loaded')\n",
    "opts = params.CNMFParams(params_dict=param_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion correction\n",
    "*if there is no existing memmap*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display movie\n",
    "# if True - Ca channel demostration on\n",
    "display_movie = True\n",
    "if display_movie:\n",
    "    m_orig = cm.load_movie_chain(file_list)\n",
    "    ds_ratio = 0.31\n",
    "    m_orig.resize(1, 1, ds_ratio).play(\n",
    "        q_max=99.5, fr=50, magnification=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start a cluster for parallel processing (if a cluster already exists it will be closed and a new session will be opened)\n",
    "if 'dview' in locals():\n",
    "    cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "                                                backend='local',\n",
    "                                                n_processes=None,\n",
    "                                                single_thread=False)\n",
    "\n",
    "mc = MotionCorrect(file_list, dview=dview, **opts.get_group('motion'))\n",
    "mc.motion_correct(save_movie=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results\n",
    "display_movie = True\n",
    "save_avi = False\n",
    "if display_movie:\n",
    "    m_orig = cm.load_movie_chain(file_list)\n",
    "    m_els = cm.load(mc.fname_tot_els)\n",
    "    ds_ratio = 0.2\n",
    "    cm.concatenate([m_orig.resize(1, 1, ds_ratio) - mc.min_mov*mc.nonneg_movie,\n",
    "                    m_els.resize(1, 1, ds_ratio)], \n",
    "                   axis=2).play(fr=30, q_max=99.5, magnification=1, offset=0, save_movie=save_avi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory map the file in order 'C' saving\n",
    "\n",
    "border_to_0 = 0 if mc.border_nan == 'copy' else mc.border_to_0 \n",
    "file_memmap = cm.save_memmap(mc.mmap_file, base_name= f'{file}', order='C',\n",
    "                        border_to_0=border_to_0) # exclude borders\n",
    "print(file_memmap, '- memmap saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save motion corrected image as TIFF\n",
    "\n",
    "def save_registered():\n",
    "    Yr, dims, T = cm.load_memmap(file_memmap)\n",
    "    ca_images = np.reshape(Yr.T, [T] + list(dims), order='F') \n",
    "    tiff.imwrite(f'{path}/{file}_reg.tif',ca_images)\n",
    "\n",
    "save_registered()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNMF fit & refit\n",
    "\n",
    "*if there is no existing refited CNMF*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MemMap Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yr, dims, T = cm.load_memmap(file_memmap)\n",
    "\n",
    "ca_images = np.reshape(Yr.T, [T] + list(dims), order='F') \n",
    "Cn = cm.local_correlations(ca_images, swap_dim=False)\n",
    "Cn[np.isnan(Cn)] = 0\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(Cn, cmap='magma')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit section"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start a cluster for parallel processing (if a cluster already exists it will be closed and a new session will be opened)\n",
    "if 'dview' in locals():\n",
    "    cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart cluster to clean up memory\n",
    "cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm = cnmf.CNMF(n_processes, params=opts, dview=dview)\n",
    "if isinstance(file_fit, str):\n",
    "    print('Loading in progress')\n",
    "    cnm = cnmf.load_CNMF(file_fit, n_processes=1, dview=dview)\n",
    "else:\n",
    "    print('Fit in progress')   \n",
    "    cnm = cnm.fit(ca_images)\n",
    "    save_results = True\n",
    "    if save_results:\n",
    "        cnm.save(f'{path}/{file}_fit.hdf5')\n",
    "\n",
    "cnm.estimates.plot_contours_nb(img=Cn, cmap='magma')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refit section"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnm.params.set('quality', {'use_cnn': False})\n",
    "\n",
    "min_size = 100              # minimal component area in px\n",
    "max_size = 512^2             # maximal component area in px\n",
    "\n",
    "cnm.estimates.evaluate_components(ca_images, cnm.params, dview=dview)\n",
    "cnm.estimates.threshold_spatial_components(maxthr=0.3, dview=dview)\n",
    "cnm.estimates.remove_small_large_neurons(min_size_neuro=min_size, max_size_neuro=max_size)\n",
    "cnm.estimates.plot_contours_nb(img=Cn, idx=cnm.estimates.idx_components, cmap='magma')\n",
    "\n",
    "print(f'{len(cnm.estimates.idx_components)} good components: {cnm.estimates.idx_components}')\n",
    "print(f'{len(cnm.estimates.idx_components_bad)} bad components: {cnm.estimates.idx_components_bad}')\n",
    "\n",
    "# cnm.estimates.select_components(idx_components=cnm.estimates.idx_components)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(file_refit, str):\n",
    "    cnm2 = cnmf.load_CNMF(file_refit, n_processes=1, dview=dview)\n",
    "else:   \n",
    "    cnm2 = cnm.refit(ca_images, dview=dview)\n",
    "\n",
    "save_results = True\n",
    "if save_results:\n",
    "    cnm2.save(f'{path}/{file}_refit.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm2.estimates.evaluate_components(ca_images, cnm.params, dview=dview)\n",
    "cnm.estimates.plot_contours_nb(img=Cn, idx=cnm.estimates.idx_components, cmap='magma')\n",
    "cnm2.estimates.plot_contours_nb(img=Cn, idx=cnm2.estimates.idx_components, cmap='magma')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final CNMF selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fin_cnm = cnm\n",
    "fin_cnm = cnm2\n",
    "print(fin_cnm.estimates.idx_components)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot & output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def df_cascade_plot(prof_arr, y_shift=0.5):\n",
    "    \"\"\" prof_arr, [prof_num, prof_val] - 2d numpy array with dF/F profiles\n",
    "\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(20, 8))\n",
    "\n",
    "    shift = 0\n",
    "    for i in prof_arr:\n",
    "        plt.plot(i+shift, alpha=.5)\n",
    "        shift += y_shift\n",
    "    plt.vlines(x=[-20], ymin=[-0.2], ymax=[0.8], linewidth=3, color='k')\n",
    "    plt.text(x=-60, y=-0.1, s=\"100% ΔF/F\", size=15, rotation=90.)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def comp_mask_plot(samp_cnmf, samp_img):\n",
    "    \"\"\" All spatial components (A) mask ctrl img\n",
    "\n",
    "    \"\"\"\n",
    "    A = samp_cnmf.estimates.A.toarray().reshape(samp_img.shape + (-1,), order='F').transpose([2, 0, 1])\n",
    "    all_A = np.zeros_like(A[0])\n",
    "\n",
    "    component_centers = {}\n",
    "    for i in samp_cnmf.estimates.idx_components:  # range(A_shape[0]):\n",
    "        A_frame = A[i]\n",
    "        A_frame != 0\n",
    "        component_centers.update({i:np.asarray(measurements.center_of_mass(A_frame), dtype=int)})\n",
    "        all_A[np.array(A_frame, dtype=bool)] = i\n",
    "\n",
    "    all_A = np.ma.masked_where(all_A == 0, all_A, copy=False)\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(samp_img, cmap='magma')\n",
    "    plt.imshow(all_A, cmap='jet', alpha=.5)\n",
    "    for component_num in component_centers.keys():\n",
    "        center_coord = component_centers[component_num]\n",
    "        plt.annotate(component_num+1, # this is the value which we want to label (text)\n",
    "                    (center_coord[1], center_coord[0]), # x and y is the points location where we have to label\n",
    "                    textcoords=\"offset points\",\n",
    "                    xytext=(2,2),\n",
    "                    ha='center',\n",
    "                    color='white')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def comp_contour_plot(samp_cnmf, samp_img):\n",
    "    \"\"\" All spatial components (A) contours overlap ctrl img\n",
    "\n",
    "    \"\"\"\n",
    "    A = samp_cnmf.estimates.A.toarray().reshape(samp_img.shape + (-1,), order='F').transpose([2, 0, 1])\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(samp_img, cmap='magma')\n",
    "\n",
    "    for i in samp_cnmf.estimates.idx_components: \n",
    "        A_frame = A[i]\n",
    "        A_frame[A_frame != 0] = 1\n",
    "        A_frame = np.ma.masked_where(A_frame == 0, A_frame, copy=False)\n",
    "        A_center = measurements.center_of_mass(A_frame)\n",
    "        A_contour = np.asarray(measure.find_contours(A_frame, level=0.5))\n",
    "\n",
    "        plt.imshow(A_frame, cmap='jet', alpha=.5)\n",
    "        plt.plot(A_contour[0][:, 1], A_contour[0][:, 0], linewidth=2)\n",
    "        plt.annotate(f'ROI {i+1}',\n",
    "                    (A_center[1], A_center[0]),\n",
    "                    textcoords=\"offset points\",\n",
    "                    xytext=(2,2),\n",
    "                    ha='center',\n",
    "                    color='white',\n",
    "                    weight='bold',\n",
    "                    fontsize=10)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def contour_grid_plot(samp_cnmf, samp_img):\n",
    "    A = samp_cnmf.estimates.A.toarray().reshape(samp_img.shape + (-1,), order='F').transpose([2, 0, 1])\n",
    "\n",
    "    w = 20\n",
    "    h = 20\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    columns = 4\n",
    "    rows = 4\n",
    "\n",
    "    for i in samp_cnmf.estimates.idx_components: \n",
    "        A_frame = A[i]\n",
    "        A_frame[A_frame != 0] = 1\n",
    "        A_frame = np.ma.masked_where(A_frame == 0, A_frame, copy=False)\n",
    "        A_contour = np.asarray(measure.find_contours(A_frame, level=0.5))\n",
    "\n",
    "    # for i in range(1, columns*rows +1):\n",
    "        img = np.random.randint(10, size=(h,w))\n",
    "        fig.add_subplot(rows, columns, i+1)\n",
    "        plt.imshow(samp_img, cmap='magma')\n",
    "        for contour in A_contour:\n",
    "            plt.plot(contour[:, 1], contour[:, 0], linewidth=1, color='r')\n",
    "        # plt.title.set_title(f'ROI {i+1}')\n",
    "        plt.title(f'ROI {i+1}')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def comp_df_plot(samp_cnmf, y_shift=0.5):\n",
    "    plt.figure(figsize=(20, 8))\n",
    "\n",
    "    shift = 0\n",
    "    for i in samp_cnmf.estimates.idx_components:\n",
    "        df_prof = samp_cnmf.estimates.F_dff[i]\n",
    "        plt.plot(df_prof+shift, alpha=.5, label=f'ROI {i+1}')\n",
    "        shift -= y_shift\n",
    "\n",
    "    plt.vlines(x=[-20], ymin=[-0.2], ymax=[0.8], linewidth=3, color='k')\n",
    "    plt.text(x=-60, y=-0.5, s=\"100% ΔF/F\", size=15, rotation=90.)\n",
    "    plt.axis('off')\n",
    "    plt.legend(loc=1)\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ΔF/F calc & ctrl plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_cnm.estimates.detrend_df_f(quantileMin=5, frames_window=500,\n",
    "                            flag_auto=True, use_fast=False, detrend_only=False)\n",
    "\n",
    "comp_contour_plot(fin_cnm, Cn)\n",
    "#contour_grid_plot(fin_cnm, Cn)\n",
    "comp_df_plot(fin_cnm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output CSV saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prof_df(samp_cnmf, samp_img, samp_name, reg_time):\n",
    "    A = samp_cnmf.estimates.A.toarray().reshape(samp_img.shape[1:] + (-1,), order='F').transpose([2, 0, 1])\n",
    "\n",
    "    # init df\n",
    "    output_df = pd.DataFrame(columns=['reg_name',      # registration name\n",
    "                                      'index',         # frame index\n",
    "                                      'time',          # registration time\n",
    "                                      'comp',          # component num\n",
    "                                      'profile_raw',   # component raw value, total mean\n",
    "                                      'profile_C',     # component denoised value\n",
    "                                      'profile_ddf'])   # component detrended ΔF/F value\n",
    "    \n",
    "    frame_num = samp_cnmf.estimates.C.shape[1]\n",
    "    i_col = range(frame_num)\n",
    "    time_col = np.linspace(0, reg_time, num=frame_num)\n",
    "    reg_name_col = np.full(frame_num, samp_name)\n",
    "\n",
    "    for component_num in samp_cnmf.estimates.idx_components:\n",
    "        component_col = np.full(ca_images.shape[0], component_num)\n",
    "        \n",
    "        A_frame = A[component_num]\n",
    "        A_mask = np.copy(A_frame)\n",
    "        A_mask != 0\n",
    "        A_mask = np.array(A_mask, dtype=bool)\n",
    "\n",
    "        # mean by spatial component mask\n",
    "        est_raw = np.asarray([np.mean(np.ma.masked_where(~A_mask, frame)) for frame in samp_img])\n",
    "\n",
    "        # temporal component\n",
    "        est_C = samp_cnmf.estimates.C[component_num]\n",
    "\n",
    "        # detrended temporal component\n",
    "        est_df = samp_cnmf.estimates.F_dff[component_num]\n",
    "        \n",
    "        component_df = pd.DataFrame({'reg_name':reg_name_col,\n",
    "                                     'index':i_col,\n",
    "                                     'time':time_col,\n",
    "                                     'comp':component_col,\n",
    "                                     'profile_raw':est_raw,\n",
    "                                     'profile_C':est_C,\n",
    "                                     'profile_ddf':est_df})\n",
    "        output_df = pd.concat([output_df, component_df], ignore_index=True)\n",
    "\n",
    "    output_df.to_csv(f'{samp_name}_microglia_dF.csv', index=False)\n",
    "    print(output_df.head())\n",
    "\n",
    "save_prof_df(samp_cnmf=fin_cnm,\n",
    "             samp_img=ca_images,\n",
    "             samp_name=f'{path}/{file}',\n",
    "             reg_time=1634.0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOP CLUSTER and clean up log files\n",
    "\n",
    "cm.stop_server(dview=dview)\n",
    "# log_files = glob.glob('*_LOG_*')\n",
    "# for log_file in log_files:\n",
    "#     os.remove(log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff stuff\n",
    "\n",
    "cnm.estimates.play_movie(ca_images, q_max=95, magnification=1, include_bck=False, use_color=False, save_movie=False)\n",
    "\n",
    "# time-series correlation: https://towardsdatascience.com/four-ways-to-quantify-synchrony-between-time-series-data-b99136c4a9c9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "29b2b70970d54890c2ecd25b23b96024fbcef9a6a76cf3bb8bb780f56e497e25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
