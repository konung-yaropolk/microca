{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a49ac22",
   "metadata": {},
   "source": [
    "# Peaks detection and features measurment\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad8eac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import logging\n",
    "import yaml\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "import numpy as np\n",
    "import numpy.polynomial.polynomial as poly\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "from scipy import ndimage\n",
    "\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16e68eba",
   "metadata": {},
   "source": [
    "## Preprocessing & parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f52689f3",
   "metadata": {},
   "source": [
    "#### Custom func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e6db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_prof_to_arr(input_df):\n",
    "    \"\"\" Normilize raw Ca profiles in 0-1 range and convert data frame to numpy array\n",
    "    Return:\n",
    "        - np array (dims - [component, raw_prof, df_prof, norm_prof])\n",
    "        - dict ({component:raw_prof})\n",
    "\n",
    "    \"\"\"\n",
    "    output_arr = []\n",
    "    output_dict = {}\n",
    "    comp_list = np.array(input_df.comp.unique())\n",
    "    for comp in comp_list:\n",
    "        comp_raw_prof = np.array(input_df['profile_raw'][input_df['comp'] == comp])\n",
    "        comp_df_prof = np.array(input_df['profile_ddf'][input_df['comp'] == comp])\n",
    "        comp_norm_prof = preprocessing.minmax_scale(comp_raw_prof)\n",
    "        output_arr.append([comp_raw_prof, comp_df_prof, comp_norm_prof])\n",
    "        output_dict.update({comp:comp_raw_prof})\n",
    "    return np.asarray(output_arr), output_dict\n",
    "\n",
    "def ctrl_plot(input_df):\n",
    "    # raw profiles view\n",
    "    fig=px.line(input_df,\n",
    "                y='profile_ddf',\n",
    "                x='time',\n",
    "                color='comp',\n",
    "                animation_frame=\"comp\",\n",
    "                title='Individual components ΔF/F profiles')\n",
    "    fig.update(layout_yaxis_range = [min(input_df.profile_ddf), max(input_df.profile_ddf)])\n",
    "    fig.update_layout(showlegend=False)\n",
    "    fig.show()\n",
    "\n",
    "def prof_peaks_plot(input_profile, peaks_i, peaks_prop, x_time=None, add_profile=None):\n",
    "    \"\"\" SciPy find_peaks results for individual profile plotting,\n",
    "    for 0-1 range scaling profile only\n",
    "\n",
    "    \"\"\"\n",
    "    # features calc\n",
    "    if x_time is None:\n",
    "        x_time = np.linspace(0, input_profile.shape[0], input_profile.shape[0])\n",
    "    prom = peaks_prop['prominences']\n",
    "    prom_h = input_profile[peaks_i] - prom\n",
    "    width_w = np.sort(np.asarray([*peaks_prop['left_bases'], *peaks_prop['right_bases']], dtype=int))\n",
    "    width_pairs =  np.asarray(list(zip(peaks_prop['left_bases'], peaks_prop['right_bases'])), dtype=int)\n",
    "    fwhm_y = peaks_prop['width_heights']\n",
    "    fwhm_l = x_time[np.asarray(peaks_prop['left_ips'], dtype=int)]\n",
    "    fwhm_r = x_time[np.asarray(peaks_prop['right_ips'], dtype=int)]\n",
    "\n",
    "    # plotting\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    plt.plot(x_time, input_profile)\n",
    "    plt.plot(x_time[peaks_i], input_profile[peaks_i], 'x', color='red')\n",
    "    plt.plot(x_time[width_w], input_profile[width_w], '.', color='red')\n",
    "    plt.vlines(x=x_time[peaks_i], ymin=prom_h, ymax=input_profile[peaks_i], color='red')\n",
    "    plt.hlines(y=fwhm_y, xmin=fwhm_l, xmax=fwhm_r, color='red')\n",
    "    plt.hlines(y=.5, xmin=0, xmax=np.max(x_time), linestyles='--', color='k')\n",
    "    plt.fill_between(x=x_time,\n",
    "                     y1=input_profile,\n",
    "                     y2=.5,\n",
    "                     color='y',\n",
    "                     alpha=.2,\n",
    "                     where=input_profile>=.5)\n",
    "    for peak_width in width_pairs:\n",
    "        plt.fill_between(x= x_time[peak_width[0]:peak_width[1]], \n",
    "                         y1= input_profile[peak_width[0]:peak_width[1]], \n",
    "                         color= \"red\",\n",
    "                         alpha= 0.2)\n",
    "    if add_profile is not None:\n",
    "        plt.plot(x_time, add_profile, color='g', alpha=.25)\n",
    "    # plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def peaks_prop_plot(input_profile, peaks_i, peaks_prop, x_time=None, add_profile=None, save_path=None):\n",
    "    \"\"\" SciPy find_peaks results for individual profile plotting,\n",
    "    for df/F profiles\n",
    "\n",
    "    \"\"\"\n",
    "    # features calc\n",
    "    if x_time is None:\n",
    "        x_time = np.linspace(0, input_profile.shape[0], input_profile.shape[0])\n",
    "    prom = peaks_prop['prominences']\n",
    "    prom_h = input_profile[peaks_i] - prom\n",
    "    width_w = np.sort(np.asarray([*peaks_prop['left_ips'], *peaks_prop['right_ips']], dtype=int))\n",
    "    width_pairs =  np.asarray(list(zip(peaks_prop['left_ips'], peaks_prop['right_ips'])), dtype=int)\n",
    "    fwhm_y = peaks_prop['width_heights']\n",
    "    fwhm_l = x_time[np.asarray(peaks_prop['left_ips'], dtype=int)]\n",
    "    fwhm_r = x_time[np.asarray(peaks_prop['right_ips'], dtype=int)]\n",
    "\n",
    "    # plotting\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    plt.plot(x_time, input_profile)\n",
    "    plt.plot(x_time[peaks_i], input_profile[peaks_i], 'x', color='red')\n",
    "    plt.plot(x_time[width_w], input_profile[width_w], '.', color='red')\n",
    "    plt.vlines(x=x_time[peaks_i], ymin=prom_h, ymax=input_profile[peaks_i], color='red')\n",
    "    plt.hlines(y=fwhm_y, xmin=fwhm_l, xmax=fwhm_r, color='red')\n",
    "    for peak_num in range(width_pairs.shape[0]):\n",
    "        peak_width = width_pairs[peak_num]\n",
    "        peak_base_val = fwhm_y[peak_num]\n",
    "        plt.fill_between(x=x_time[peak_width[0]:peak_width[1]], \n",
    "                         y1=input_profile[peak_width[0]:peak_width[1]],\n",
    "                         y2=np.full((peak_width[1]-peak_width[0]), peak_base_val), \n",
    "                         color=\"red\",\n",
    "                         alpha=0.2)\n",
    "    if add_profile is not None:\n",
    "        plt.plot(x_time, add_profile, color='g', alpha=.25)\n",
    "    plt.tight_layout()\n",
    "    # plt.legend()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "def cascade_plot(input_df, time, line_dict, y_shift=0.5, save_path=None):\n",
    "    \"\"\" prof_arr, [prof_num, prof_val] - 2d numpy array with dF/F profiles\n",
    "\n",
    "    \"\"\"\n",
    "    list_ROI = np.array(input_df.comp.unique())\n",
    "    time_bar = int(200 * (max(time)/len(time)))\n",
    "\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    \n",
    "    # profiles plotting\n",
    "    shift = 0\n",
    "    for num_ROI in list_ROI:\n",
    "        prof_ROI = np.array(input_df['profile_ddf'][input_df['comp'] == num_ROI])\n",
    "        plt.plot(time, prof_ROI+shift, alpha=.5, label=f'ROI {num_ROI}')\n",
    "        shift -= y_shift\n",
    "\n",
    "    # bars plotting\n",
    "    first_prof_max = np.array(input_df['profile_ddf'][input_df['comp'] == list_ROI[0]]).max()\n",
    "\n",
    "    for line_name in line_dict:\n",
    "        if line_name == 'ctrl':\n",
    "            continue\n",
    "        line_lim = line_dict[line_name]\n",
    "        plt.plot(line_lim, [first_prof_max+0.05] * len(line_lim), label=line_name, linewidth=4)\n",
    "\n",
    "    plt.vlines(x=[-10], ymin=[first_prof_max-(1+0.15)], ymax=[first_prof_max+0.15], linewidth=3, color='k')\n",
    "    # plt.text(x=-30, y=-0.2, s=\"100% ΔF/F\", size=15, rotation=90.)\n",
    "\n",
    "    plt.hlines(y=[first_prof_max+0.15], xmin=[-10], xmax=[time_bar-10], linewidth=3, color='k')\n",
    "    # plt.text(x=30, y=-1.15, s=\"200 s\", size=15)\n",
    "\n",
    "    plt.title('x bar - 200s, y bar - 100% ΔF/F', loc='left')\n",
    "    plt.axis('off')\n",
    "    plt.legend(loc=1)\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(f'{save_path}/components_profile_selected.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65d06f4c",
   "metadata": {},
   "source": [
    "#### Data & sample global parameters uploading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ad0669",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_name = 'E0003'\n",
    "samp_path = os.path.join(''.join(sys.path[0].split('glia')), 'data_glia', samp_name)\n",
    "\n",
    "\n",
    "# sample data frame uploading\n",
    "total_df = pd.read_csv(f'{samp_path}/{samp_name}_components_df.csv')\n",
    "total_arr, _ = norm_prof_to_arr(total_df)\n",
    "print(total_df.head())\n",
    "\n",
    "# sample YAML metadata file uploading\n",
    "with open(f'{samp_path}/{samp_name}_meta.yaml') as f:\n",
    "    samp_meta = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "# time parameters (from meta file)\n",
    "total_reg_t = samp_meta['Reg_time']\n",
    "frame_time = total_reg_t / max(total_df['frame_num'])\n",
    "time_line = np.linspace(0, total_reg_t, num=max(total_df['frame_num'])+1)\n",
    "\n",
    "# treatment parameters (from meta file)\n",
    "treatment_dict = {}\n",
    "for samp in samp_meta['Events']:\n",
    "    treat_name = samp['Type']\n",
    "    start_time = samp['Time']/1000\n",
    "    treatment_dict.update({treat_name:start_time})\n",
    "keys = list(treatment_dict.keys())\n",
    "vals = list(treatment_dict.values()) + [total_reg_t]\n",
    "treatment_dict = {keys[i]:[vals[i], vals[i+1]] for i in range(len(keys))}\n",
    "treatment_dict.update({'ctrl':[0., list(treatment_dict.values())[0][0]]})\n",
    "# for k,v in treatment_dict.items():  # app time print\n",
    "#     print(k, ':', np.around(v, 1))\n",
    "application_lines_dict = {t:np.linspace(treatment_dict[t][0], treatment_dict[t][1]) for t in treatment_dict}\n",
    "\n",
    "# peaks detection parameters (from meta file)\n",
    "peaks_det_meta = samp_meta['Peaks_det']\n",
    "bad_prof_list = list(peaks_det_meta['Bad_prof'])\n",
    "print(f'Bad profiles: {bad_prof_list}')\n",
    "\n",
    "ctrl_plot(total_df)\n",
    "total_df = total_df[~total_df['comp'].isin(bad_prof_list)]  # drop bad profiles\n",
    "\n",
    "cascade_plot(total_df, time_line, application_lines_dict, save_path=samp_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b03ea06c",
   "metadata": {},
   "source": [
    "## Peaks detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a062580a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(peaks_det_meta)\n",
    "# detection options\n",
    "min_distance_sec = peaks_det_meta['Min_dist_sec']\n",
    "min_distance_frames = int(min_distance_sec / frame_time)\n",
    "if min_distance_frames < 1:\n",
    "    min_distance_frames = 1\n",
    "\n",
    "# duration options\n",
    "width_sec = peaks_det_meta['Width_sec']  # [min, max]\n",
    "width_frames = np.asanyarray([width_sec[0]/frame_time, width_sec[1]/frame_time], dtype=int)\n",
    "\n",
    "# prominence calc window option\n",
    "wlen_sec = peaks_det_meta['Wlen_sec']\n",
    "wlen_frames = int(wlen_sec / frame_time)\n",
    "\n",
    "\n",
    "# profiles img saving path\n",
    "img_path = f'{samp_path}/peaks_prop'\n",
    "if not os.path.exists(img_path):\n",
    "    os.makedirs(img_path)\n",
    "\n",
    "# peaks features data frame init\n",
    "pf_df = pd.DataFrame(columns=['sample',     # sample name\n",
    "                              'comp',       # spatial component ID\n",
    "                              'app_group',  # application group, based on meta file\n",
    "                              'peak_i',     # peal index in profile, frames\n",
    "                              'peak_time',  # peak time, sec\n",
    "                              'rise',       # rise time, sec\n",
    "                              'decay',      # decay time, sec\n",
    "                              'FWHM',       # full width at half maximum, sec\n",
    "                              'amp_abs',    # absolute amplitude, a.u.\n",
    "                              'AUC_abs',    # area ubder a curve in rise-decay window, a.u.\n",
    "                              'amp_dF',     # amplitude, ΔF/F\n",
    "                              'AUC_dF'])     # area ubder a curve in rise-decay window, ΔF/F\n",
    "\n",
    "# loop over all profiles\n",
    "components_ID = np.array(total_df.comp.unique())\n",
    "for component in components_ID:\n",
    "    det_prof = np.asarray(total_df['profile_ddf'][total_df['comp'] == component])\n",
    "    raw_prof = np.asarray(total_df['profile_raw'][total_df['comp'] == component])\n",
    "\n",
    "    # peaks detection\n",
    "    peaks, properties = signal.find_peaks(det_prof,\n",
    "                                        height=np.max(det_prof)*peaks_det_meta['Heigh_min_proc'],\n",
    "                                        threshold=None,\n",
    "                                        distance=min_distance_frames,\n",
    "                                        wlen=wlen_frames,\n",
    "                                        prominence=(np.max(det_prof)-np.min(det_prof))*peaks_det_meta['Prom_min_proc'],\n",
    "                                        rel_height=0.95,\n",
    "                                        width=width_frames)\n",
    "\n",
    "    # FWHM calc\n",
    "    fwhm_properties = signal.peak_widths(det_prof, peaks, wlen=wlen_frames)\n",
    "\n",
    "    # profile peaks plot\n",
    "    peaks_prop_plot(input_profile=det_prof, peaks_i=peaks, peaks_prop=properties, x_time=time_line,\n",
    "                    add_profile=None, save_path=f'{img_path}/ROI{component}_prof_prop.png')\n",
    "\n",
    "    # loop over app peaks\n",
    "    for peak_num in range(len(peaks)):\n",
    "        peak_index = peaks[peak_num]\n",
    "        peak_time = time_line[peak_index]\n",
    "\n",
    "        # treatment group\n",
    "        for treatment in treatment_dict.keys():\n",
    "            treatment_time = list(treatment_dict[treatment])\n",
    "            if peak_time >= treatment_time[0] and peak_time < treatment_time[1]:\n",
    "                app_group = treatment\n",
    "            else:\n",
    "               continue \n",
    "\n",
    "        # time features section\n",
    "        rise = (peak_index - properties['left_bases'][peak_num]) * frame_time\n",
    "        decay = (properties['right_bases'][peak_num] - peak_index) * frame_time\n",
    "        fwhm = fwhm_properties[0][peak_num]\n",
    "\n",
    "        # amplitude values\n",
    "        amp_abs = raw_prof[peak_index]\n",
    "        amp_dF = det_prof[peak_index]\n",
    "        \n",
    "        # signal integral section\n",
    "        peak_bool_mask = np.zeros_like(det_prof, dtype=bool)\n",
    "        peak_bool_mask[properties['left_bases'][peak_num]:properties['right_bases'][peak_num]] = 1\n",
    "        auc_abs = np.sum(raw_prof, where=peak_bool_mask)\n",
    "        auc_dF = np.sum(det_prof, where=peak_bool_mask)        \n",
    "    \n",
    "        # data frame update\n",
    "        pf_row = pd.DataFrame({'sample':[samp_name],     # sample name\n",
    "                               'comp':[component],       # spatial component ID\n",
    "                               'app_group':[app_group],  # application group, based on meta file\n",
    "                               'peak_i':[peak_index],    # peal index in profile, frames\n",
    "                               'peak_time':[peak_time],  # peak time, sec\n",
    "                               'rise':[rise],            # rise time, sec\n",
    "                               'decay':[decay],          # decay time, sec\n",
    "                               'FWHM':[fwhm],            # full width at half maximum, sec\n",
    "                               'amp_abs':[amp_abs],      # absolute amplitude, a.u.\n",
    "                               'AUC_abs':[auc_abs],      # area ubder a curve in rise-decay window, a.u.\n",
    "                               'amp_dF':[amp_dF],        # amplitude, ΔF/F\n",
    "                               'AUC_dF':[auc_dF]})       # area ubder a curve in rise-decay window, ΔF/F     \n",
    "        pf_df = pd.concat([pf_df, pf_row], ignore_index=True)\n",
    "\n",
    "print(pf_df)\n",
    "pf_df.to_csv(f'{samp_path}/peaks_properties_df.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caiman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "29b2b70970d54890c2ecd25b23b96024fbcef9a6a76cf3bb8bb780f56e497e25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
